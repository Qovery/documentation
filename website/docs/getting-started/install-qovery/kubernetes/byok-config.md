---
last_modified_on: "2024-01-11"
title: "Configuration"
description: "Configure Qovery BYOK on your Kubernetes cluster"
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

import Steps from '@site/src/components/Steps';
import Alert from '@site/src/components/Alert';

Qovery BYOK is a set of Kubernetes components that you can configure to fit your needs. It is used to connect your Kubernetes cluster to Qovery control plane.

<!--
     THIS FILE IS AUTOGENERATED!

     To make changes please edit the template located at:

     website/docs/getting-started/install-qovery/kubernetes/byok-config.md.erb
-->

## Components

<p align="center">
  <img src="/img/qovery_byok_how_it_works.jpg" alt="How Qovery works with Self Managed Kubernetes cluster" />
</p>

They are two types of components:

Qovery components:
- Qovery Control Plane: the Qovery Control Plane is the brain of Qovery. It is responsible for managing your applications and providing the API to interact with Qovery.
- Qovery Cluster Agent (mandatory): the Qovery Cluster Agent is responsible for securely forwarding logs and metrics from your Kubernetes cluster to Qovery control plane.
- Qovery Shell Agent (mandatory): the Qovery Shell Agent is responsible for giving you a secure remote shell access to your Kubernetes pods if you need it. E.g. when using `qovery shell` command.
- Qovery Engine (optional): the Qovery Engine is responsible for managing your applications deployment on your Kubernetes cluster. It can be used Qovery side or is installed on your Kubernetes cluster.

Third-party components:
- NGINX Ingress Controller (optional)
- External DNS (optional)
- Loki (optional)
- Promtail (optional)
- Cert Manager (optional)
- ...

You can choose what you want to install and manage, and you will have a description of what services are used, and responsible for. You can disable them if you don't want to use them. And you can even install other components if you want to.

## Configuration

### Qovery

This is the configuration of Qovery itself. It is used by all Qovery components.

<Alert type="danger">

**Do not share the jwtToken! Keep it in a safe place.** It is used to authenticate the cluster.

</Alert>

| Key                        | Required | Description                                                    | Default                   |
|----------------------------|----------|----------------------------------------------------------------|---------------------------|
| `qovery.clusterId`         | Yes      | The cluster ID. It is used to identify your cluster.           | `set-by-customer`         |
| `qovery.shortClusterId`    | Yes      | The short cluster ID. It is used to identify your cluster.     | `set-by-customer`         |
| `qovery.organizationId`    | Yes      | The organization ID. It is used to identify your organization. | `set-by-customer`         |
| `qovery.jwtToken`          | Yes      | The JWT token. It is used to authenticate your cluster.        | `set-by-customer`         |
| `qovery.domain`            | Yes      | The domain name used by Qovery.                                | `set-by-customer`         |
| `qovery.qoveryDnsUrl`      | Yes      | Qovery DNS url in case you want to use Qovery provided DNS     | `set-by-customer`         |
| `qovery.lokiUrl`           | No       | Local Loki URL (required if Loki is set)                       | `set-by-customer`         |
| `qovery.promtailLokiUrl`   | No       | Promtail Loki URL (required if Promtail and Loki are set)      | `set-by-customer`         |
| `qovery.acmeEmailAddr`     | No       | Email address used for `Let's Encrypt` TLS requests            | `set-by-customer`         |
| `qovery.externalDnsPrefix` | No       | ExernalDNS TXT record prefix (required if ExternalDNS is set)  | `set-by-customer`         |
| `qovery.architectures`     | No       | Set cluster architectures (comma separated)                    | `AMD64`                   |

#### Qovery Cluster Agent

|                 |                                                                                                                                    |
|-----------------|------------------------------------------------------------------------------------------------------------------------------------|
| **Required**    | Yes                                                                                                                                |
| **If deployed** | The cluster agent is responsible for securely forwarding logs and metrics from your Kubernetes cluster to Qovery control plane     |
| **If missing**  | The cluster will not report to Qovery control plane Kubernetes information, so the Qovery console will report unknown satus values |


```yaml
qovery-cluster-agent:
  fullnameOverride: qovery-cluster-agent
```

#### Qovery Shell Agent

|                 |                                                                                                                     |
|-----------------|---------------------------------------------------------------------------------------------------------------------|
| **Required**    | Yes                                                                                                                 |
| **If deployed** | Used to give a remote shell access to you Kubernetes pods (if user is allowed from Qovery RBAC) with the Qovery CLI |
| **If missing**  | No remote connection will be possible, and Qovery support will not be able to help you to diagnose issues           |

```yaml
qovery-shell-agent:
  fullnameOverride: qovery-shell-agent
```

### Ingress

| | |
|-----------------|-------------------------------|
| **Required**    | No (but strongly recommended) |
| **If deployed** | Web services can be privately or publicly exposed |
| **If missing**  | No web services will be exposed |

Qovery us will be exposed [NGINX Ingress Controller](https://docs.nginx.com/nginx-ingress-controller/) by default to route traffic to your applications.

#### Nginx Ingress Controller

<Tabs
  centered={true}
  className={"rounded"}
  defaultValue={"demo"}
  placeholder="Select a platform"
  select={false}
  size={null}
  values={[
    {"group":"NginxIngress","label":"Demo","value":"demo"},
    {"group":"NginxIngress","label":"AWS","value":"aws"},
    {"group":"NginxIngress","label":"GCP","value":"gcp"},
    {"group":"NginxIngress","label":"Scaleway","value":"scaleway"},
  ]}>

<TabItem value="demo">

Here is the minimum override configuration to be used:

```yaml
ingress-nginx:
  fullnameOverride: ingress-nginx
  controller:
    useComponentLabel: true
    admissionWebhooks:
      enabled: false
    # Ingress class used when an application/container with public access is set
    ingressClass: nginx-qovery
    extraArgs:
      # Default TLS certificate name and path
      default-ssl-certificate: "qovery/letsencrypt-acme-qovery-cert"
    # Allows customization of the source of the IP address or FQDN to report in the ingress status field
    publishService:
      enabled: true
```
</TabItem>

<TabItem value="aws">

Here is an example with Nginx Ingress Controller on AWS with NLB:

```yaml
ingress-nginx:
  controller:
    useComponentLabel: true
    admissionWebhooks:
      enabled: set-by-customer
    # enable if you want metrics scrapped by prometheus
    metrics:
      enabled: set-by-customer
      serviceMonitor:
        enabled: set-by-customer
    config:
      # set global default file size limit to 100m
      proxy-body-size: 100m
      # hide Nginx version
      server-tokens: "false"
    # the Ingress Class name to be used by Ingresses (use "nginx-qovery" for Qovery application/container deployments)
    ingressClass: nginx-qovery
    extraArgs:
      # Kubernetes path of the default Cert-manager TLS certificate (if used)
      default-ssl-certificate: "cert-manager/letsencrypt-acme-qovery-cert"
    updateStrategy:
      rollingUpdate:
        # set the minimum acceptable number of unavailable pods during a rolling update
        maxUnavailable: 1
    # enable auoscaling if you want to scale the number of replicas based on CPU usage
    autoscaling:
      enabled: true
      minReplicas: set-by-customer
      maxReplicas: set-by-customer
      targetCPUUtilizationPercentage: set-by-customer
    # required if you rely on a load balancer
    # the controller mirrors the address of this service's endpoints to the load-balancer status of all Ingress objects it satisfies.
    publishService:
      enabled: true
    # set a load balancer if you want your Nginx to be publicly accessible
    service:
      enabled: true
      annotations:
        service.beta.kubernetes.io/aws-load-balancer-type: nlb
        # Qovery managed DNS requieres *.$domain (something like: *.<cluster_id>.<given_dns_name>)
        external-dns.alpha.kubernetes.io/hostname: "set-by-customer"
      externalTrafficPolicy: "Local"
      sessionAffinity: ""
      healthCheckNodePort: 0
```

</TabItem>

<TabItem value="gcp">

Here is an example with Nginx Ingress Controller on AWS with NLB:

```yaml
ingress-nginx:
  controller:
    useComponentLabel: true
    admissionWebhooks:
      enabled: set-by-customer
    # enable if you want metrics scrapped by prometheus
    metrics:
      enabled: set-by-customer
      serviceMonitor:
        enabled: set-by-customer
    config:
      # set global default file size limit to 100m
      proxy-body-size: 100m
      # hide Nginx version
      server-tokens: "false"
    # the Ingress Class name to be used by Ingresses (use "nginx-qovery" for Qovery application/container deployments)
    ingressClass: nginx-qovery
    extraArgs:
      # Kubernetes path of the default Cert-manager TLS certificate (if used)
      default-ssl-certificate: "qovery/letsencrypt-acme-qovery-cert"
    updateStrategy:
      rollingUpdate:
        # set the minimum acceptable number of unavailable pods during a rolling update
        maxUnavailable: 1
    # enable auoscaling if you want to scale the number of replicas based on CPU usage
    autoscaling:
      enabled: true
      minReplicas: set-by-customer
      maxReplicas: set-by-customer
      targetCPUUtilizationPercentage: set-by-customer
    # required if you rely on a load balancer
    # the controller mirrors the address of this service's endpoints to the load-balancer status of all Ingress objects it satisfies.
    publishService:
      enabled: true
    # set a load balancer if you want your Nginx to be publicly accessible
    service:
      enabled: true
      annotations:
        # Qovery managed DNS requieres *.$domain (something like: *.<cluster_id>.<given_dns_name>)
        external-dns.alpha.kubernetes.io/hostname: "set-by-customer"
      externalTrafficPolicy: "Local"
      sessionAffinity: ""
      healthCheckNodePort: 0
```

</TabItem>

<TabItem value="scaleway">

Here is an example with Nginx Ingress Controller on Scaleway:

```yaml
ingress-nginx:
  controller:
    useComponentLabel: true
    admissionWebhooks:
      enabled: set-by-customer
    # enable if you want metrics scrapped by prometheus
    metrics:
      enabled: set-by-customer
      serviceMonitor:
        enabled: set-by-customer
    config:
      # set global default file size limit to 100m
      proxy-body-size: 100m
      # hide Nginx version
      server-tokens: "false"
      # required for X-Forwarded-for to work
      use-proxy-protocol: "true"
    # the Ingress Class name to be used by Ingresses (use "nginx-qovery" for Qovery application/container deployments)
    ingressClass: nginx-qovery
    extraArgs:
      # Kubernetes path of the default Cert-manager TLS certificate (if used)
      default-ssl-certificate: "cert-manager/letsencrypt-acme-qovery-cert"
    updateStrategy:
      rollingUpdate:
        # set the minimum acceptable number of unavailable pods during a rolling update
        maxUnavailable: 1
    # enable auoscaling if you want to scale the number of replicas based on CPU usage
    autoscaling:
      enabled: true
      minReplicas: set-by-customer
      maxReplicas: set-by-customer
      targetCPUUtilizationPercentage: set-by-customer
    # required if you rely on a load balancer
    # the controller mirrors the address of this service's endpoints to the load-balancer status of all Ingress objects it satisfies.
    publishService:
      enabled: true
    # set a load balancer if you want your Nginx to be publicly accessible
    service:
      enabled: true
      # https://github.com/scaleway/scaleway-cloud-controller-manager/blob/master/docs/loadbalancer-annotations.md
      annotations:
        service.beta.kubernetes.io/scw-loadbalancer-forward-port-algorithm: "leastconn"
        service.beta.kubernetes.io/scw-loadbalancer-protocol-http: "false"
        service.beta.kubernetes.io/scw-loadbalancer-proxy-protocol-v1: "false"
        service.beta.kubernetes.io/scw-loadbalancer-proxy-protocol-v2: "true"
        service.beta.kubernetes.io/scw-loadbalancer-health-check-type: tcp
        service.beta.kubernetes.io/scw-loadbalancer-use-hostname: "true"
        # set Scaleway load balancer type https://www.scaleway.com/en/load-balancer/ (ex: LB-GP-S, LB-GP-M, LB-GP-L, LB-GP-XL)
        service.beta.kubernetes.io/scw-loadbalancer-type: "set-by-customer"
        # Qovery managed DNS requieres *.$domain (something like: *.<cluster_id>.<given_dns_name>)
        external-dns.alpha.kubernetes.io/hostname: "set-by-customer"
      externalTrafficPolicy: "Local"
```

</TabItem>

</Tabs>

#### Other Ingress Controllers

Qovery supports other Ingress Controllers. Please contact us if you want to use another one. We will be happy to help you.

### DNS

| | |
|-----------------|-------------------------------|
| **Required**    | No (but strongly recommended) |
| **If deployed** | Used to easily reach your applications with DNS records, even on private network |
| **If missing**  | You will have easy access with dns names to your services, you'll have to use IPs |

Qovery uses [External DNS](https://github.com/kubernetes-sigs/external-dns) to automatically configure DNS records for your applications.

If you don't want or can't add your own DNS provider, Qovery proposes it's own managed sub-domain DNS provider for free.
You'll then be able to later add your custom DNS record (no matter the provider) to point to your Qovery DNS sub-domain.

#### External DNS

<Tabs
  centered={true}
  className={"rounded"}
  defaultValue={"demo"}
  placeholder="Select a platform"
  select={false}
  size={null}
  values={[
    {"group":"ExternalDns","label":"Demo & QoveryDNS","value":"demo"},
    {"group":"ExternalDns","label":"Cloudflare","value":"cloudflare"},
  ]}>

<TabItem value="demo">

Here is one example with Qovery DNS provider:
```yaml
external-dns:
  fullnameOverride: external-dns
  # set pdns for Qovery DNS managed (or you can use any supported provider by external-dns)
  provider: pdns
  # will use the domain name given by Qovery during the cluster setup phease
  domainFilters: [*domain]
  # an owner ID is set to avoid conflicts in case of multiple Qovery clusters
  txtOwnerId: *shortClusterId
  # a prefix to help Qovery to debug in case of issues
  txtPrefix: *externalDnsPrefix
  # set the Qovery DNS provider configuration
  pdns:
    apiUrl: *qoveryDnsUrl
    apiKey: *jwtToken
    apiPort: 443
```

</TabItem>

<TabItem value="cloudflare">

Here is one example with Cloudflare:
```yaml
external-dns:
  # set the provider to use
  provider: set-by-customer
  # keep the config you want to use and remove the others. Configure the provider you want to use.
  cloudflare:
    apiToken: set-by-customer
    email: set-by-customer
    proxied: set-by-customer
  pdns:
    # Qovery DNS: apiUrl: *qoveryDnsUrl
    apiUrl: set-by-customer
    # Qovery DNS: apiPort: "443"
    apiPort: set-by-customer
    # Qovery DNS: apiKey: "443"
    apiKey: set-by-customer
  # Make external DNS ignore this ingress https://github.com/kubernetes-sigs/external-dns/issues/1910#issuecomment-976371247
  annotationFilter: external-dns.alpha.kubernetes.io/exclude notin (true)
  # set domainFilters to the domain you want to manage: [*domain]
  domainFilters: set-by-customer
  triggerLoopOnEvent: true
  policy: sync
  # avoid dns collision with other external-dns instances
  txtOwnerId: set-by-customer
  txtPrefix: set-by-customer
  # set the number of replicas you want to use
  replicas: 1
  # set the rolling update strategy you want to apply
  updateStrategy:
    type: set-by-customer
  # remove if you don't want to use a custom image
  image:
    registry: set-by-customer
    repository: set-by-customer
    tag: 0.13.2-debian-11-r17
  # set resources
  resources:
    limits:
      cpu: 50m
      memory: 100Mi
    requests:
      cpu: 50m
      memory: 100Mi
```

</TabItem>

</Tabs>

### Logging

|                 |                                                                            |
|-----------------|----------------------------------------------------------------------------|
| **Required**    | No (but strongly recommended)                                              |
| **If deployed** | Retrieve and store application's log history                               |
| **If missing**  | You'll have live logs, but you will miss log history for debugging purpose |

Qovery uses [Loki](https://grafana.com/oss/loki/) to store your logs in a S3 compatible bucket and [Promtail](https://grafana.com/docs/loki/latest/clients/promtail/) to collect your logs.

#### Loki
<Tabs
  centered={true}
  className={"rounded"}
  defaultValue={"demo"}
  placeholder="Select a platform"
  select={false}
  size={null}
  values={[
    {"group":"Loki","label":"Demo","value":"demo"},
    {"group":"Loki","label":"AWS S3","value":"s3"},
  ]}>

<TabItem value="demo">

Here is a configuration **in Memory (no persistence)** for Loki:

```yaml
loki:
  fullnameOverride: loki
  loki:
    # no auth is set for internal cluster usage
    auth_enabled: false
    ingester:
      lifecycler:
        ring:
          kvstore:
            # we store it in memory for the demo, you'll lose history once Loki restarts
            store: inmemory
          replication_factor: 1
    schema_config:
      configs:
        - from: 2020-05-15
          store: boltdb-shipper
          object_store: filesystem
          schema: v11
          index:
            prefix: index_
            period: 24h
  monitoring:
    # all the monitoring part is disabled to reduce resource footprint for the demo usage
    dashboards:
      enabled: false
    rules:
      enabled: false
    serviceMonitor:
      enabled: false
      metricsInstance:
        enabled: false
    selfMonitoring:
      enabled: false
      grafanaAgent:
        installOperator: false
    grafanaAgent:
      enabled: false
    lokiCanary:
      enabled: false
  test:
    enabled: false
  gateway:
    enabled: false
  # we use a single binary to reduce resource footprint for the demo usage
  singleBinary:
    replicas: 1
    persistence:
      enabled: false
    extraVolumes:
      - name: data
        emptyDir: {}
      - name: storage
        emptyDir: {}
    extraVolumeMounts:
      - name: data
        mountPath: /data
      - name: storage
        mountPath: /var/loki
```

</TabItem>

<TabItem value="s3">

Here is a configuration example with AWS S3 as storage backend:

```yaml
loki:
  # remove if you don't want to use a custom image
  kubectlImage:
    registry: set-by-customer
    repository: set-by-customer
  loki:
    # remove if you don't want to use a custom image
    image:
      registry: set-by-customer
      repository: set-by-customer
    # set if you want to use authentication
    auth_enabled: false
    commonConfig:
      # for simple usage, without high throughput, you can use the 1 replica only
      # note: replication is assured by the storage backend
      replication_factor: 1
    ingester:
      chunk_idle_period: 3m
      chunk_block_size: 262144
      chunk_retain_period: 1m
      max_transfer_retries: 0
      lifecycler:
        ring:
          kvstore:
            store: memberlist
          replication_factor: 1
    memberlist:
      abort_if_cluster_join_fails: false
      bind_port: 7946
      join_members:
        # set loki headless service
        - loki-headless.logging.svc:7946
      max_join_backoff: 1m
      max_join_retries: 10
      min_join_backoff: 1s
    limits_config:
      ingestion_rate_mb: 20
      ingestion_burst_size_mb: 30
      enforce_metric_name: false
      reject_old_samples: true
      reject_old_samples_max_age: 168h
      max_concurrent_tail_requests: 100
      split_queries_by_interval: 15m
      max_query_lookback: 12w
    compactor:
      working_directory: /data/retention
      # configure storage provider for the compactor
      shared_store: aws
      compaction_interval: 10m
      retention_enabled: set-by-customer
      retention_delete_delay: 2h
      retention_delete_worker_count: 150
    table_manager:
      retention_deletes_enabled: set-by-customer
      retention_period: set-by-customer
    schema_config:
      configs:
        # set the schema for the index (2020 version can be deleted on a fresh install)
        - from: 2020-05-15
          store: boltdb-shipper
          object_store: s3
          schema: v11
          index:
            prefix: index_
            period: 24h
        - from: 2023-06-01
          store: boltdb-shipper
          object_store: s3
          schema: v12
          index:
            prefix: index_
            period: 24h
    storage:
      # configure the object storage backend
      bucketNames:
        chunks:
        ruler:
        admin:
      type: s3
      s3:
        s3:
        region:
        s3ForcePathStyle:
        insecure:
    storage_config:
      boltdb_shipper:
        active_index_directory: /data/loki/index
        shared_store: s3
        resync_interval: 5s
        cache_location: /data/loki/boltdb-cache
  monitoring:
    dashboards:
      enabled: false
    rules:
      enabled: false
    serviceMonitor:
      enabled: false
      metricsInstance:
        enabled: false
    selfMonitoring:
      enabled: false
      grafanaAgent:
        installOperator: false
    grafanaAgent:
      enabled: false
    lokiCanary:
      enabled: false
  test:
    enabled: false
  gateway:
    enabled: false
  # set the single binary version for basic usage
  singleBinary:
    replicas: 1
    # set resources
    resources:
      limits:
        cpu: 1
        memory: 2Gi
      requests:
        cpu: 300m
        memory: 1Gi
    persistence:
      enabled: false
    extraVolumes:
      - name: data
        emptyDir: {}
      - name: storage
        emptyDir: {}
    extraVolumeMounts:
      - name: data
        mountPath: /data
      - name: storage
        mountPath: /var/loki
    # set disk persistence to reduce data loss in case of pod crash
    # persistence:
    #   storageClass: set-by-customer
  serviceAccount:
    annotations: {}
```

</TabItem>

</Tabs>

#### Promtail

A configuration example compatible with all providers:

```yaml
promtail:
  fullnameOverride: promtail
  # promtail requires to be spawned in kube-system namespace
  namespace: kube-system
  priorityClassName: system-node-critical
  config:
    clients:
      # forward logs to Loki
      - url: *promtailLokiUrl
    snippets:
      extraRelabelConfigs:
        - action: labelmap
          # required to be able to watch logs from Qovery console interface
          regex: __meta_kubernetes_pod_label_(qovery_com_service_id|qovery_com_service_type|qovery_com_environment_id)
```

### Certificates

|                 |                                                                        |
|-----------------|------------------------------------------------------------------------|
| **Required**    | No (but strongly recommended)                                          |
| **If deployed** | Cert-manager helps you to get TLS certificates through Let's Encrypt   |
| **If missing**  | Without it, you will not be able to automatically get TLS certificates |

Qovery uses [Cert Manager](https://cert-manager.io/) to automatically get TLS certificates for your applications.

#### Cert Manager

Here is the minimal setup for all cloud providers:

```yaml
cert-manager:
  fullnameOverride: cert-manager
  # CRD are required
  installCRDs: true
  replicaCount: 1
  startupapicheck:
    jobAnnotations:
      helm.sh/hook: post-install,post-upgrade
    rbac:
      annotations:
        helm.sh/hook: post-install,post-upgrade
    serviceAccount:
      annotations:
        helm.sh/hook: post-install,post-upgrade
```

#### Qovery Cert Manager Webhook

|                 |                                                                                                 |
|-----------------|-------------------------------------------------------------------------------------------------|
| **Required**    | No (but if you're using Qovery DNS Provider)                                                    |
| **If deployed** | Required to get Let's Encrypt TLS if Qovery DNS Provider is used                                |
| **If missing**  | Without it, you will not be able to automatically get TLS certificates with Qovery DNS Provider |

<Tabs
  centered={true}
  className={"rounded"}
  defaultValue={"qovery"}
  placeholder="Select a platform"
  select={false}
  size={null}
  values={[
    {"group":"QoveryCertManagerWebhook","label":"Qovery DNS","value":"qovery"},
    {"group":"QoveryCertManagerWebhook","label":"","value":""},
  ]}>

<TabItem value="qovery">

A configuration example compatible with all providers:

```yaml
qovery-cert-manager-webhook:
  fullnameOverride: qovery-cert-manager-webhook
  certManager:
    # set the same namespace than cert-manager
    namespace: qovery
    serviceAccountName: cert-manager
  secret:
    apiUrl: *qoveryDnsUrl
    apiKey: *jwtToken
```

</TabItem>
</Tabs>

#### Cert Manager Configs

|                 |                                                                                    |
|-----------------|------------------------------------------------------------------------------------|
| **Required**    | No                                                                                 |
| **If deployed** | This is an helper to deploy cert-manager config. But you can manually set it       |
| **If missing**  | Installing Cert-manager is not enough, you have to configure it to get TLS working |

<Tabs
  centered={true}
  className={"rounded"}
  defaultValue={"demo"}
  placeholder="Select a platform"
  select={false}
  size={null}
  values={[
    {"group":"ExternalDns","label":"Demo","value":"demo"},
    {"group":"ExternalDns","label":"Qovery DNS","value":"qovery"},
    {"group":"ExternalDns","label":"Cloudflare","value":"cloudflare"},
  ]}>

<TabItem value="demo">

This is the configuration of Cert Manager itself. It is used by all Cert Manager components.

```yaml
cert-manager-configs:
  fullnameOverride: cert-manager-configs
  # set pdns to use Qovery DNS provider
  externalDnsProvider: pdns
  managedDns: [*domain]
  acme:
    letsEncrypt:
      emailReport: *acmeEmailAddr
      # As it's a demo cluster, we use the staging environment to avoid rate limit issues
      acmeUrl: https://acme-staging-v02.api.letsencrypt.org/directory
  provider:
    # set the provider of your choice or use the Qovery DNS provider
    pdns:
      apiPort: 443
      apiUrl: *qoveryDnsUrl
      apiKey: *jwtToken
```

</TabItem>

<TabItem value="qovery">

This is the configuration of Cert Manager itself. It is used by all Cert Manager components.

```yaml
cert-manager-configs:
  fullnameOverride: cert-manager-configs
  # set pdns to use Qovery DNS provider
  externalDnsProvider: pdns
  managedDns: [*domain]
  acme:
    letsEncrypt:
      emailReport: *acmeEmailAddr
      # set the Let's Encrypt URL
      # Test: https://acme-staging-v02.api.letsencrypt.org/directory
      # Prod: https://acme-v02.api.letsencrypt.org/directory
      acmeUrl: https://acme-v02.api.letsencrypt.org/directory
  provider:
    # set the provider of your choice or use the Qovery DNS provider
    pdns:
      apiPort: 443
      apiUrl: *qoveryDnsUrl
      apiKey: *jwtToken
```

</TabItem>

<TabItem value="cloudflare">

This is the configuration of Cert Manager itself. It is used by all Cert Manager components.

```yaml
cert-manager-configs:
  fullnameOverride: cert-manager-configs
  # set pdns to use Qovery DNS provider
  externalDnsProvider: cloudflare
  managedDns: [*domain]
  acme:
    letsEncrypt:
      emailReport: *acmeEmailAddr
      acmeUrl: https://acme-v02.api.letsencrypt.org/directory
  provider:
    cloudflare:
      apiToken: "set your Cloudflare API token here"
      email: "set your Cloudflare email here"
```

</TabItem>

</Tabs>

Qovery uses [Metrics Server](https://github.com/kubernetes-sigs/metrics-server) to collect metrics from your Kubernetes cluster and scale your applications automatically based on custom metrics.

## Observability

### Metrics Server

|                 |                                                                                                                                |
|-----------------|--------------------------------------------------------------------------------------------------------------------------------|
| **Required**    | No (but strongly recommended)                                                                                                  |
| **If deployed** | Mandatory if you want to retrive pod metrics for the Qovery agent and if you want to be able to use the horizontal pod scaling |
| **If missing**  | No HPA and no application metrics in the QOveyr console                                                                        |

<Tabs
  centered={true}
  className={"rounded"}
  defaultValue={"demo"}
  placeholder="Select a platform"
  select={false}
  size={null}
  values={[
    {"group":"MetricsServer","label":"Demo","value":"demo"},
    {"group":"MetricsServer","label":"AWS","value":"aws"},
    {"group":"MetricsServer","label":"GCP","value":"gcp"},
    {"group":"MetricsServer","label":"Scaleway","value":"scaleway"},
  ]}>

<TabItem value="aws">

```yaml
metrics-server:
  # create api service to be able to use hpa/vpa
  apiService:
    create: true
  # set rolling restart strategy
  updateStrategy:
    type: set-by-customer
  # set resources
  resources:
    limits:
      cpu: set-by-customer
      memory: set-by-customer
    requests:
      cpu: set-by-customer
      memory: set-by-customer
```

</TabItem>

<TabItem value="gcp">

Nothing needs to be deployed, as GCP already provides a managed metrics server.

</TabItem>

<TabItem value="scaleway">

Nothing needs to be deployed, as Scaleway already provides a managed metrics server.

</TabItem>

<TabItem value="demo">

```yaml
metrics-server:
  fullnameOverride: metrics-server
  defaultArgs:
    - --cert-dir=/tmp
    - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
    - --kubelet-use-node-status-port
    - --metric-resolution=15s
    - --kubelet-insecure-tls
  apiService:
    create: false
```

</TabItem>
</Tabs>



